{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d1F9PWvrjUt"
   },
   "source": [
    "# Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvaoqR3MrjUv"
   },
   "source": [
    "## Wstęp\n",
    "\n",
    "Celem laboratorium jest zapoznanie się z podstawami sieci neuronowych oraz uczeniem głębokim (*deep learning*). Zapoznasz się na nim z następującymi tematami:\n",
    "- treningiem prostych sieci neuronowych, w szczególności z:\n",
    "  - regresją liniową w sieciach neuronowych\n",
    "  - optymalizacją funkcji kosztu\n",
    "  - algorytmem spadku wzdłuż gradientu\n",
    "  - siecią typu Multilayer Perceptron (MLP)\n",
    "- frameworkiem PyTorch, w szczególności z:\n",
    "  - ładowaniem danych\n",
    "  - preprocessingiem danych\n",
    "  - pisaniem pętli treningowej i walidacyjnej\n",
    "  - walidacją modeli\n",
    "- architekturą i hiperaprametrami sieci MLP, w szczególności z:\n",
    "  - warstwami gęstymi (w pełni połączonymi)\n",
    "  - funkcjami aktywacji\n",
    "  - regularyzacją: L2, dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c9fO45ErjUw"
   },
   "source": [
    "## Wykorzystywane biblioteki\n",
    "\n",
    "Zaczniemy od pisania ręcznie prostych sieci w bibliotece Numpy, służącej do obliczeń numerycznych na CPU. Później przejdziemy do wykorzystywania frameworka PyTorch, służącego do obliczeń numerycznych na CPU, GPU oraz automatycznego różniczkowania, wykorzystywanego głównie do treningu sieci neuronowych.\n",
    "\n",
    "Wykorzystamy PyTorcha ze względu na popularność, łatwość instalacji i użycia, oraz dużą kontrolę nad niskopoziomowymi aspektami budowy i treningu sieci neuronowych. Framework ten został stworzony do zastosowań badawczych i naukowych, ale ze względu na wygodę użycia stał się bardzo popularny także w przemyśle. W szczególności całkowicie zdominował przetwarzanie języka naturalnego (NLP) oraz uczenie na grafach.\n",
    "\n",
    "Pierwszy duży framework do deep learningu, oraz obecnie najpopularniejszy, to TensorFlow, wraz z wysokopoziomową nakładką Keras. Są jednak szanse, że Google (autorzy) będzie go powoli porzucać na rzecz ich nowego frameworka JAX ([dyskusja](https://www.reddit.com/r/MachineLearning/comments/vfl57t/d_google_quietly_moving_its_products_from/), [artykuł Business Insidera](https://www.businessinsider.com/facebook-pytorch-beat-google-tensorflow-jax-meta-ai-2022-6?IR=T)), który jest bardzo świeżym, ale ciekawym narzędziem.\n",
    "\n",
    "Trzecia, ale znacznie mniej popularna od powyższych opcja to Apache MXNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz_20Lw4rjUx"
   },
   "source": [
    "## Konfiguracja własnego komputera\n",
    "\n",
    "Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane).\n",
    "\n",
    "Jeżeli nie masz GPU lub nie chcesz z niego korzystać, to wystarczy znaleźć odpowiednią komendę CPU [na stronie PyTorcha](https://pytorch.org/get-started/locally/). Dla Anacondy odpowiednia komenda została podana poniżej, dla pip'a znajdź ją na stronie.\n",
    "\n",
    "Jeżeli chcesz korzystać ze wsparcia GPU (na tym laboratorium nie będzie potrzebne, na kolejnych może przyspieszyć nieco obliczenia), to musi być to odpowiednio nowa karta NVidii, mająca CUDA compatibility ([lista](https://developer.nvidia.com/cuda-gpus)). Poza PyTorchem będzie potrzebne narzędzie NVidia CUDA w wersji 11.6 lub 11.7. Instalacja na Windowsie jest bardzo prosta (wystarczy ściągnąć plik EXE i zainstalować jak każdy inny program). Instalacja na Linuxie jest trudna i można względnie łatwo zepsuć sobie system, ale jeżeli chcesz spróbować, to [ten tutorial](https://www.youtube.com/results?search_query=nvidia+cuda+install+ubuntu+20.04) jest bardzo dobry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "awrAcFF7rjUx"
   },
   "outputs": [],
   "source": [
    "# for conda users\n",
    "# !conda install -y matplotlib pandas pytorch torchvision -c pytorch -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Othm3C2lLAsj"
   },
   "source": [
    "## Wprowadzenie\n",
    "\n",
    "Zanim zaczniemy naszą przygodę z sieciami neuronowymi, przyjrzyjmy się prostemu przykładowi regresji liniowej na syntetycznych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rnJsfxbnLAsj"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "EaYpEXzBLAsl",
    "outputId": "d63c339f-d87e-430f-88ad-a42d45125eea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7d57a7f7d240>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = x + np.random.normal(scale=0.1, size=x.shape)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEM_-yKELAsl"
   },
   "source": [
    "W przeciwieństwie do laboratorium 1, tym razem będziemy chcieli rozwiązać ten problem własnoręcznie, bez użycia wysokopoziomowego interfejsu Scikit-learn'a. W tym celu musimy sobie przypomnieć sformułowanie naszego **problemu optymalizacyjnego (optimization problem)**.\n",
    "\n",
    "W przypadku prostej regresji liniowej (1 zmienna) mamy model postaci $\\hat{y} = \\alpha x + \\beta$, z dwoma parametrami, których będziemy się uczyć. Miarą niedopasowania modelu o danych parametrach jest **funkcja kosztu (cost function)**, nazywana też funkcją celu. Najczęściej używa się **błędu średniokwadratowego (mean squared error, MSE)**:\n",
    "$$\\large\n",
    "MSE = \\frac{1}{N} \\sum_{i}^{N} (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "Od jakich $\\alpha$ i $\\beta$ zacząć? W najprostszym wypadku wystarczy po prostu je wylosować jako niewielkie liczby zmiennoprzecinkowe.\n",
    "\n",
    "#### Zadanie 1 (0.5 punkt)\n",
    "\n",
    "Uzupełnij kod funkcji `mse`, obliczającej błąd średniokwadratowy. Wykorzystaj Numpy'a w celu wektoryzacji obliczeń dla wydajności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "RaA7Q46TLAsm"
   },
   "outputs": [],
   "source": [
    "def mse(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    return np.sum((y - y_hat) ** 2) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "qSGfamGbLAsm",
    "outputId": "9c8b98a2-32db-44d3-f2ca-b1cb026612d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7d57a7dd09d0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand()\n",
    "b = np.random.rand()\n",
    "print(f\"MSE: {mse(y, a * x + b):.3f}\")\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y--E9Mp9LAsn"
   },
   "source": [
    "Losowe parametry radzą sobie nie najlepiej. Jak lepiej dopasować naszą prostą do danych? Zawsze możemy starać się wyprowadzić rozwiązanie analitycznie, i w tym wypadku nawet nam się uda. Jest to jednak szczególny i dość rzadki przypadek, a w szczególności nie będzie to możliwe w większych sieciach neuronowych.\n",
    "\n",
    "Potrzebna nam będzie **metoda optymalizacji (optimization method)**, dającą wartości parametrów minimalizujące dowolną różniczkowalną funkcję kosztu. Zdecydowanie najpopularniejszy jest tutaj **spadek wzdłuż gradientu (gradient descent)**.\n",
    "\n",
    "Metoda ta wywodzi się z prostych obserwacji, które tutaj przedstawimy. Bardziej szczegółowe rozwinięcie dla zainteresowanych: [sekcja 4.3 \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/numerical.html), [ten praktyczny kurs](https://cs231n.github.io/optimization-1/), [analiza oryginalnej publikacji Cauchy'ego](https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf) (oryginał w języku francuskim).\n",
    "\n",
    "Pochodna jest dokładnie równa granicy funkcji. Dla małego $\\epsilon$ można ją przybliżyć jako:\n",
    "$$\\large\n",
    "\\frac{f(x)}{dx} \\approx \\frac{f(x+\\epsilon) - f(x)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "Przyglądając się temu równaniu widzimy, że:\n",
    "* dla funkcji rosnącej ($f(x+\\epsilon) > f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak dodatni\n",
    "* dla funkcji malejącej ($f(x+\\epsilon) < f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak ujemny\n",
    "\n",
    "Widzimy więc, że potrafimy wskazać kierunek zmniejszenia wartości funkcji, patrząc na znak pochodnej. Zaobserwowano także, że amplituda wartości w $\\frac{f(x)}{dx}$ jest tym większa, im dalej jesteśmy od minimum (maximum). Pochodna wyznacza więc, w jakim kierunku funkcja najszybciej rośnie, zaś przeciwny zwrot to ten, w którym funkcja najszybciej spada.\n",
    "\n",
    "Stosując powyższe do optymalizacji, mamy:\n",
    "$$\\large\n",
    "x_{t+1} = x_{t} -  \\alpha * \\frac{f(x)}{dx}\n",
    "$$\n",
    "\n",
    "$\\alpha$ to niewielka wartość (rzędu zwykle $10^{-5}$ - $10^{-2}$), wprowadzona, aby trzymać się założenia o małej zmianie parametrów ($\\epsilon$). Nazywa się ją **stałą uczącą (learning rate)** i jest zwykle najważniejszym hiperparametrem podczas nauki sieci.\n",
    "\n",
    "Metoda ta zakłada, że używamy całego zbioru danych do aktualizacji parametrów w każdym kroku, co nazywa się po prostu GD (od *gradient descent*) albo *full batch GD*. Wtedy każdy krok optymalizacji nazywa się **epoką (epoch)**.\n",
    "\n",
    "Im większa stała ucząca, tym większe nasze kroki podczas minimalizacji. Możemy więc uczyć szybciej, ale istnieje ryzyko, że będziemy \"przeskakiwać\" minima. Mniejsza stała ucząca to wolniejszy, ale dokładniejszy trening. Jednak nie zawsze ona pozwala osiągnąć lepsze wyniki, bo może okazać się, że utkniemy w minimum lokalnym. Można także zmieniać stałą uczącą podczas treningu, co nazywa się **learning rate scheduling (LR scheduling)**. Obrazowo:\n",
    "\n",
    "![learning_rate](http://www.bdhammel.com/assets/learning-rate/lr-types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "496qEjkVLAso"
   },
   "source": [
    "![interactive LR](http://cdn-images-1.medium.com/max/640/1*eeIvlwkMNG1wSmj3FR6M2g.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYkyAHKzLAsp"
   },
   "source": [
    "Policzmy więc pochodną dla naszej funkcji kosztu MSE. Pochodną liczymy po parametrach naszego modelu, bo to właśnie ich chcemy dopasować tak, żeby koszt był jak najmniejszy:\n",
    "\n",
    "$$\\large\n",
    "MSE = \\frac{1}{N} \\sum_{i}^{N} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "W powyższym wzorze tylko $y_i$ jest zależny od $a$ oraz $b$. Możemy wykorzystać tu regułę łańcuchową (*chain rule*) i policzyć pochodne po naszych parametrach w sposób następujący:\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} a} = \\frac{1}{N} \\sum_{i}^{N} \\frac{\\text{d} (y_i - \\hat{y_i})^2}{\\text{d} \\hat{y_i}} \\frac{\\text{d} \\hat{y_i}}{\\text{d} a}\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} b} = \\frac{1}{N} \\sum_{i}^{N} \\frac{\\text{d} (y_i - \\hat{y_i})^2}{\\text{d} \\hat{y_i}} \\frac{\\text{d} \\hat{y_i}}{\\text{d} b}\n",
    "$$\n",
    "\n",
    "Policzmy te pochodne po kolei:\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} (y_i - \\hat{y_i})^2}{\\text{d} \\hat{y_i}} = -2 \\cdot (y_i - \\hat{y_i})\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y_i}}{\\text{d} a} = x_i\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y_i}}{\\text{d} b} = 1\n",
    "$$\n",
    "\n",
    "Łącząc powyższe wyniki dostaniemy:\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} a} = \\frac{-2}{N} \\sum_{i}^{N} (y_i - \\hat{y_i}) \\cdot {x_i}\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} b} = \\frac{-2}{N} \\sum_{i}^{N} (y_i - \\hat{y_i})\n",
    "$$\n",
    "\n",
    "Aktualizacja parametrów wygląda tak:\n",
    "\n",
    "$$\\large\n",
    "a' = a - \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) \\cdot x_i \\right)\n",
    "$$\n",
    "$$\\large\n",
    "b' = b - \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) \\right)\n",
    "$$\n",
    "\n",
    "Liczymy więc pochodną funkcji kosztu, a potem za pomocą reguły łańcuchowej \"cofamy się\", dochodząc do tego, jak każdy z parametrów wpływa na błąd i w jaki sposób powinniśmy go zmienić. Nazywa się to **propagacją wsteczną (backpropagation)** i jest podstawowym mechanizmem umożliwiającym naukę sieci neuronowych za pomocą spadku wzdłuż gradientu. Więcej możesz o tym przeczytać [tutaj](https://cs231n.github.io/optimization-2/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqXRZWDUrjU2"
   },
   "source": [
    "\n",
    "#### Zadanie 2 (1.0 punkt)\n",
    "\n",
    "Zaimplementuj funkcję realizującą jedną epokę treningową. Zauważ, że `x` oraz `y` są wektorami. Oblicz predykcję przy aktualnych parametrach oraz zaktualizuj je zgodnie z powyższymi wzorami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4qbdWOSULAsp"
   },
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    x: np.ndarray, y: np.ndarray, a: float, b: float, learning_rate: float = 0.1\n",
    "):\n",
    "    y_hat = a * x + b\n",
    "    errors = y - y_hat\n",
    "    return a - (learning_rate * (-2 * np.sum(errors * x)) / x.size), b - (\n",
    "        learning_rate * (-2 * np.sum(errors)) / x.size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSrZVyl6rjU2",
    "outputId": "c69764f1-963c-4d31-bde7-3d89e671cd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  0.1330225119404028\n",
      "step 100 loss:  0.012673197778527677\n",
      "step 200 loss:  0.010257153540857817\n",
      "step 300 loss:  0.0100948037549359\n",
      "step 400 loss:  0.010083894412889118\n",
      "step 500 loss:  0.010083161342973332\n",
      "step 600 loss:  0.010083112083219709\n",
      "step 700 loss:  0.010083108773135261\n",
      "step 800 loss:  0.010083108550709076\n",
      "step 900 loss:  0.01008310853576281\n",
      "final loss: 0.010083108534760455\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "    a, b = optimize(x, y, a, b)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqfjvC8n_UTU",
    "outputId": "5a66dc28-6206-4eed-87bb-9004b55a45b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "assert 0.0 < loss < 2.0\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "xOgRcPC1LAsq",
    "outputId": "361d0967-680a-4a1e-a341-379cb1797acd",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7d57ac4ad0c0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOr2fWYpLAsq"
   },
   "source": [
    "Udało ci się wytrenować swoją pierwszą sieć neuronową. Czemu? Otóż neuron to po prostu wektor parametrów, a zwykle robimy iloczyn skalarny tych parametrów z wejściem. Dodatkowo na wyjście nakłada się **funkcję aktywacji (activation function)**, która przekształca wyjście. Tutaj takiej nie było, a właściwie była to po prostu funkcja identyczności.\n",
    "\n",
    "Oczywiście w praktyce korzystamy z odpowiedniego frameworka, który w szczególności:\n",
    "- ułatwia budowanie sieci, np. ma gotowe klasy dla warstw neuronów\n",
    "- ma zaimplementowane funkcje kosztu oraz ich pochodne\n",
    "- sam różniczkuje ze względu na odpowiednie parametry i aktualizuje je odpowiednio podczas treningu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJBYJabuLAsr"
   },
   "source": [
    "## Wprowadzenie do PyTorcha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB-99XqhLAsr"
   },
   "source": [
    "PyTorch to w gruncie rzeczy narzędzie do algebry liniowej z [automatycznym rożniczkowaniem](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html), z możliwością przyspieszenia obliczeń z pomocą GPU. Na tych fundamentach zbudowany jest pełny framework do uczenia głębokiego. Można spotkać się ze stwierdzenie, że PyTorch to NumPy + GPU + opcjonalne różniczkowanie, co jest całkiem celne. Plus można łatwo debugować printem :)\n",
    "\n",
    "PyTorch używa dynamicznego grafu obliczeń, który sami definiujemy w kodzie. Takie podejście jest bardzo wygodne, elastyczne i pozwala na łatwe eksperymentowanie. Odbywa się to potencjalnie kosztem wydajności, ponieważ pozostawia kwestię optymalizacji programiście. Więcej na ten temat dla zainteresowanych na końcu laboratorium.\n",
    "\n",
    "Samo API PyTorcha bardzo przypomina Numpy'a, a podstawowym obiektem jest `Tensor`, klasa reprezentująca tensory dowolnego wymiaru. Dodatkowo niektóre tensory będą miały automatycznie obliczony gradient. Co ważne, tensor jest na pewnym urządzeniu, CPU lub GPU, a przenosić między nimi trzeba explicite.\n",
    "\n",
    "Najważniejsze moduły:\n",
    "- `torch` - podstawowe klasy oraz funkcje, np. `Tensor`, `from_numpy()`\n",
    "- `torch.nn` - klasy związane z sieciami neuronowymi, np. `Linear`, `Sigmoid`\n",
    "- `torch.optim` - wszystko związane z optymalizacją, głównie spadkiem wzdłuż gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FwuIt8S-LAss"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfCiUFXULAss",
    "outputId": "32f8ba8c-745b-492b-f76f-44efd8f20995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6725, 1.2626, 1.9016, 1.5920, 1.0812, 1.6254, 1.1206, 1.6045, 1.4348,\n",
      "        1.2388])\n",
      "tensor([0.6725, 0.2626, 0.9016, 0.5920, 0.0812, 0.6254, 0.1206, 0.6045, 0.4348,\n",
      "        0.2388])\n",
      "tensor(4.5341)\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(10)\n",
    "noise = torch.ones(10) * torch.rand(10)\n",
    "\n",
    "# elementwise sum\n",
    "print(ones + noise)\n",
    "\n",
    "# elementwise multiplication\n",
    "print(ones * noise)\n",
    "\n",
    "# dot product\n",
    "print(ones @ noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOE4JisF_igL",
    "outputId": "8a0a9824-68ec-4767-d639-f693732e43ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ynNd_kD0LAst"
   },
   "outputs": [],
   "source": [
    "# beware - shares memory with original Numpy array!\n",
    "# very fast, but modifications are visible to original variable\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9kkxczELAsu"
   },
   "source": [
    "Jeżeli dla stworzonych przez nas tensorów chcemy śledzić operacje i obliczać gradient, to musimy oznaczyć `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HtZL-KfLAsu",
    "outputId": "64f0a8dc-98e4-4b0f-f3bb-9377dc89f6e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2439], requires_grad=True), tensor([0.5921], requires_grad=True))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl1guWZ_LAsv"
   },
   "source": [
    "PyTorch zawiera większość powszechnie używanych funkcji kosztu, np. MSE. Mogą być one używane na 2 sposoby, z czego pierwszy jest popularniejszy:\n",
    "- jako klasy wywoływalne z modułu `torch.nn`\n",
    "- jako funkcje z modułu `torch.nn.functional`\n",
    "\n",
    "Po wykonaniu poniższego kodu widzimy, że zwraca on nam tensor z dodatkowymi atrybutami. Co ważne, jest to skalar (0-wymiarowy tensor), bo potrzebujemy zwyczajnej liczby do obliczania propagacji wstecznych (pochodnych czątkowych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HfXFQ1arjU5",
    "outputId": "93d01305-51d3-44f8-87fa-aebaa842e78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(y, a * x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS35r49nLAsw"
   },
   "source": [
    "Atrybutu `grad_fn` nie używamy wprost, bo korzysta z niego w środku PyTorch, ale widać, że tensor jest \"świadomy\", że liczy się na nim pochodną. Możemy natomiast skorzystać z atrybutu `grad`, który zawiera faktyczny gradient. Zanim go jednak dostaniemy, to trzeba powiedzieć PyTorchowi, żeby policzył gradient. Służy do tego metoda `.backward()`, wywoływana na obiekcie zwracanym przez funkcję kosztu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Qb7l6Xg1LAsx"
   },
   "outputs": [],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LfQbLVoLAsx",
    "outputId": "6b0e6dab-4bda-4f42-9005-863401be8737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0846])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kdf1iweELAsy"
   },
   "source": [
    "Ważne jest, że PyTorch nie liczy za każdym razem nowego gradientu, tylko dodaje go do istniejącego, czyli go akumuluje. Jest to przydatne w niektórych sieciach neuronowych, ale zazwyczaj trzeba go zerować. Jeżeli tego nie zrobimy, to dostaniemy coraz większe gradienty.\n",
    "\n",
    "Do zerowania służy metoda `.zero_()`. W PyTorchu wszystkie metody modyfikujące tensor w miejscu mają `_` na końcu nazwy. Jest to dość niskopoziomowa operacja dla pojedynczych tensorów - zobaczymy za chwilę, jak to robić łatwiej dla całej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiCQZKJsLAsy",
    "outputId": "6eed2ddf-5838-4774-ae22-cb450b68fd76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1692])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNC3Ag8uLAsz"
   },
   "source": [
    "Zobaczmy, jak wyglądałaby regresja liniowa, ale napisana w PyTorchu. Jest to oczywiście bardzo niskopoziomowa implementacja - za chwilę zobaczymy, jak to wygląda w praktyce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKnxyeboLAsz",
    "outputId": "2a6a7779-474c-4e8f-d904-25fc42532f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 100 loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 200 loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 300 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 400 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 500 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 600 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 700 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 800 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 900 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    a.data -= learning_rate * a.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "\n",
    "    # zero gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DXNVhshmmI-"
   },
   "source": [
    "Trening modeli w PyTorchu jest dosyć schematyczny i najczęściej rozdziela się go na kilka bloków, dających razem **pętlę uczącą (training loop)**, powtarzaną w każdej epoce:\n",
    "1. Forward pass - obliczenie predykcji sieci\n",
    "2. Loss calculation\n",
    "3. Backpropagation - obliczenie pochodnych oraz zerowanie gradientów\n",
    "4. Optimalization - aktualizacja wag\n",
    "5. Other - ewaluacja na zbiorze walidacyjnym, logging etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2etpw7TNLAs0",
    "outputId": "ad5e6b3a-1206-4579-af98-6778235f4f92",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss: 0.2025\n",
      "step 100 loss: 0.0126\n",
      "step 200 loss: 0.0103\n",
      "step 300 loss: 0.0101\n",
      "step 400 loss: 0.0101\n",
      "step 500 loss: 0.0101\n",
      "step 600 loss: 0.0101\n",
      "step 700 loss: 0.0101\n",
      "step 800 loss: 0.0101\n",
      "step 900 loss: 0.0101\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "learning_rate = 0.1\n",
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([a, b], lr=learning_rate)\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "# training loop in each epoch\n",
    "for i in range(1000):\n",
    "    # forward pass\n",
    "    y_hat = a * x + b\n",
    "\n",
    "    # loss calculation\n",
    "    loss = mse(y, y_hat)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # optimization\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()  # zeroes all gradients - very convenient!\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        if loss < best_loss:\n",
    "            best_model = (a.clone(), b.clone())\n",
    "            best_loss = loss\n",
    "        print(f\"step {i} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk0PGAIVrjU7"
   },
   "source": [
    "Przejdziemy teraz do budowy sieci neuronowej do klasyfikacji. Typowo implementuje się ją po prostu jako sieć dla regresji, ale zwracającą tyle wyników, ile mamy klas, a potem aplikuje się na tym funkcję sigmoidalną (2 klasy) lub softmax (>2 klasy). W przypadku klasyfikacji binarnej zwraca się czasem tylko 1 wartość, przepuszczaną przez sigmoidę - wtedy wyjście z sieci to prawdopodobieństwo klasy pozytywnej.\n",
    "\n",
    "Funkcją kosztu zwykle jest **entropia krzyżowa (cross-entropy)**, stosowana też w klasycznej regresji logistycznej. Co ważne, sieci neuronowe, nawet tak proste, uczą się szybciej i stabilniej, gdy dane na wejściu (a przynajmniej zmienne numeryczne) są **ustandaryzowane (standardized)**. Operacja ta polega na odjęciu średniej i podzieleniu przez odchylenie standardowe (tzw. *Z-score transformation*).\n",
    "\n",
    "**Uwaga - PyTorch wymaga tensora klas będącego liczbami zmiennoprzecinkowymi!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57CNYpdRrjU8"
   },
   "source": [
    "## Zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOIqrbbfrjVF"
   },
   "source": [
    "Na tym laboratorium wykorzystamy zbiór [Adult Census](https://archive.ics.uci.edu/ml/datasets/adult). Dotyczy on przewidywania na podstawie danych demograficznych, czy dany człowiek zarabia powyżej 50 tysięcy dolarów rocznie, czy też mniej. Jest to cenna informacja np. przy planowaniu kampanii marketingowych. Jak możesz się domyślić, zbiór pochodzi z czasów, kiedy inflacja była dużo niższa :)\n",
    "\n",
    "Poniżej znajduje się kod do ściągnięcia i preprocessingu zbioru. Nie musisz go dokładnie analizować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DNsaZAnLAs0",
    "outputId": "1ebb169d-d42a-4e73-f917-3edaf6aa9028",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-27 15:51:23--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified\n",
      "Saving to: ‘adult.data.1’\n",
      "\n",
      "adult.data.1            [  <=>               ]   3.79M  16.8MB/s    in 0.2s    \n",
      "\n",
      "2024-11-27 15:51:24 (16.8 MB/s) - ‘adult.data.1’ saved [3974305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uU69HlSbrjVF",
    "outputId": "7917aaa8-4dfb-49bf-dd9b-4d8c64dffced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"wage\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "age: continuous.\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous.\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "sex: Female, Male.\n",
    "capital-gain: continuous.\n",
    "capital-loss: continuous.\n",
    "hours-per-week: continuous.\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"adult.data\", header=None, names=columns)\n",
    "df.wage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tps-xfXdrjVG",
    "outputId": "15dc7a65-97b9-4158-d043-787c301f2146"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-34a60972a90f>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Preschool', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('10th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('11th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('12th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('1st-4th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('5th-6th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('7th-8th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('9th', 'dropout',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('HS-Grad', 'HighGrad',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('HS-grad', 'HighGrad',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Some-college', 'CommunityCollege',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Assoc-acdm', 'CommunityCollege',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Assoc-voc', 'CommunityCollege',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Bachelors', 'Bachelors',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Masters', 'Masters',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Prof-school', 'Masters',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education'].replace('Doctorate', 'Doctorate',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['marital-status'].replace('Never-married', 'NotMarried',inplace=True)\n",
      "<ipython-input-59-34a60972a90f>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['marital-status'].replace(['Married-AF-spouse'], 'Married',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# attribution: https://www.kaggle.com/code/royshih23/topic7-classification-in-python\n",
    "df[\"education\"].replace(\"Preschool\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"10th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"11th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"12th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"1st-4th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"5th-6th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"7th-8th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"9th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"HS-Grad\", \"HighGrad\", inplace=True)\n",
    "df[\"education\"].replace(\"HS-grad\", \"HighGrad\", inplace=True)\n",
    "df[\"education\"].replace(\"Some-college\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Assoc-acdm\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Assoc-voc\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Bachelors\", \"Bachelors\", inplace=True)\n",
    "df[\"education\"].replace(\"Masters\", \"Masters\", inplace=True)\n",
    "df[\"education\"].replace(\"Prof-school\", \"Masters\", inplace=True)\n",
    "df[\"education\"].replace(\"Doctorate\", \"Doctorate\", inplace=True)\n",
    "\n",
    "df[\"marital-status\"].replace(\"Never-married\", \"NotMarried\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-AF-spouse\"], \"Married\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-civ-spouse\"], \"Married\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-spouse-absent\"], \"NotMarried\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Separated\"], \"Separated\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Divorced\"], \"Separated\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Widowed\"], \"Widowed\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiOxs_6mLAs1",
    "outputId": "478c0b23-a340-4913-d3f8-c7a352fdf1a0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20838, 108), (20838,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "X = df.copy()\n",
    "y = (X.pop(\"wage\") == \" >50K\").astype(int).values\n",
    "\n",
    "train_valid_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=train_valid_size, random_state=0, shuffle=True, stratify=y\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=train_valid_size,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    stratify=y_train,\n",
    ")\n",
    "\n",
    "continuous_cols = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"education-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "continuous_X_train = X_train[continuous_cols]\n",
    "categorical_X_train = X_train.loc[:, ~X_train.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_valid = X_valid[continuous_cols]\n",
    "categorical_X_valid = X_valid.loc[:, ~X_valid.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_test = X_test[continuous_cols]\n",
    "categorical_X_test = X_test.loc[:, ~X_test.columns.isin(continuous_cols)]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "continuous_scaler = StandardScaler()  # MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "categorical_encoder.fit(categorical_X_train)\n",
    "continuous_scaler.fit(continuous_X_train)\n",
    "\n",
    "continuous_X_train = continuous_scaler.transform(continuous_X_train)\n",
    "continuous_X_valid = continuous_scaler.transform(continuous_X_valid)\n",
    "continuous_X_test = continuous_scaler.transform(continuous_X_test)\n",
    "\n",
    "categorical_X_train = categorical_encoder.transform(categorical_X_train)\n",
    "categorical_X_valid = categorical_encoder.transform(categorical_X_valid)\n",
    "categorical_X_test = categorical_encoder.transform(categorical_X_test)\n",
    "\n",
    "X_train = np.concatenate([continuous_X_train, categorical_X_train], axis=1)\n",
    "X_valid = np.concatenate([continuous_X_valid, categorical_X_valid], axis=1)\n",
    "X_test = np.concatenate([continuous_X_test, categorical_X_test], axis=1)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv2-pK_1rjVH"
   },
   "source": [
    "Uwaga co do typów - PyTorchu wszystko w sieci neuronowej musi być typu `float32`. W szczególności trzeba uważać na konwersje z Numpy'a, który używa domyślnie typu `float64`. Może ci się przydać metoda `.float()`.\n",
    "\n",
    "Uwaga co do kształtów wyjścia - wejścia do `nn.BCELoss` muszą być tego samego kształtu. Może ci się przydać metoda `.squeeze()` lub `.unsqueeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qfRA3xEoLAs1"
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float().unsqueeze(-1)\n",
    "\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "y_valid = torch.from_numpy(y_valid).float().unsqueeze(-1)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1HVXA_JrjVH"
   },
   "source": [
    "Podobnie jak w laboratorium 2, mamy tu do czynienia z klasyfikacją niezbalansowaną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "tczS-IffrjVH",
    "outputId": "c076cdb3-ecaf-4194-a987-a34a8c62f178"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pos_perc = 100 * y_train.sum().item() / len(y_train)\n",
    "y_neg_perc = 100 - y_pos_perc\n",
    "\n",
    "plt.title(\"Class percentages\")\n",
    "plt.bar([\"<50k\", \">=50k\"], [y_neg_perc, y_pos_perc])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ_iiyC1rjVI"
   },
   "source": [
    "W związku z powyższym będziemy używać odpowiednich metryk, czyli AUROC, precyzji i czułości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLexWff-LAs0"
   },
   "source": [
    "#### Zadanie 3 (1.0 punkt)\n",
    "\n",
    "Zaimplementuj regresję logistyczną dla tego zbioru danych, używając PyTorcha. Dane wejściowe zostały dla ciebie przygotowane w komórkach poniżej.\n",
    "\n",
    "Sama sieć składa się z 2 elementów:\n",
    "- warstwa liniowa `nn.Linear`, przekształcająca wektor wejściowy na 1 wyjście - logit\n",
    "- aktywacja sigmoidalna `nn.Sigmoid`, przekształcająca logit na prawdopodobieństwo klasy pozytywnej\n",
    "\n",
    "Użyj binarnej entropii krzyżowej `nn.BCELoss` jako funkcji kosztu. Użyj optymalizatora SGD ze stałą uczącą `1e-3`. Trenuj przez 3000 epok. Pamiętaj, aby przekazać do optymalizatora `torch.optim.SGD` parametry sieci (metoda `.parameters()`). Dopisz logowanie kosztu raz na 100 epok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbABKz5-LAs2",
    "outputId": "eee07966-fcdc-45e0-9275-ecee0c1f0f89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6336\n",
      "Epoch 100, Loss: 0.6107\n",
      "Epoch 200, Loss: 0.5914\n",
      "Epoch 300, Loss: 0.5749\n",
      "Epoch 400, Loss: 0.5606\n",
      "Epoch 500, Loss: 0.5483\n",
      "Epoch 600, Loss: 0.5374\n",
      "Epoch 700, Loss: 0.5279\n",
      "Epoch 800, Loss: 0.5193\n",
      "Epoch 900, Loss: 0.5117\n",
      "Epoch 1000, Loss: 0.5047\n",
      "Epoch 1100, Loss: 0.4984\n",
      "Epoch 1200, Loss: 0.4926\n",
      "Epoch 1300, Loss: 0.4873\n",
      "Epoch 1400, Loss: 0.4824\n",
      "Epoch 1500, Loss: 0.4778\n",
      "Epoch 1600, Loss: 0.4735\n",
      "Epoch 1700, Loss: 0.4695\n",
      "Epoch 1800, Loss: 0.4657\n",
      "Epoch 1900, Loss: 0.4622\n",
      "Epoch 2000, Loss: 0.4589\n",
      "Epoch 2100, Loss: 0.4557\n",
      "Epoch 2200, Loss: 0.4527\n",
      "Epoch 2300, Loss: 0.4498\n",
      "Epoch 2400, Loss: 0.4471\n",
      "Epoch 2500, Loss: 0.4445\n",
      "Epoch 2600, Loss: 0.4420\n",
      "Epoch 2700, Loss: 0.4397\n",
      "Epoch 2800, Loss: 0.4374\n",
      "Epoch 2900, Loss: 0.4352\n",
      "final loss: tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 3000\n",
    "model = nn.Linear(in_features=X_test.shape[1], out_features=1)\n",
    "activation = nn.Sigmoid()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    y_pred = activation(model(X_train))\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Epoch {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6kGVu9vrjVI"
   },
   "source": [
    "Teraz trzeba sprawdzić, jak poszło naszej sieci. W PyTorchu sieć pracuje zawsze w jednym z dwóch trybów: treningowym lub ewaluacyjnym (predykcyjnym). Ten drugi wyłącza niektóre mechanizmy, które są używane tylko podczas treningu, w szczególności regularyzację dropout. Do przełączania służą metody modelu `.train()` i `.eval()`.\n",
    "\n",
    "Dodatkowo podczas liczenia predykcji dobrze jest wyłączyć liczenie gradientów, bo nie będą potrzebne, a oszczędza to czas i pamięć. Używa się do tego menadżera kontekstu `with torch.no_grad():`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH37zDX4LAs2",
    "outputId": "5e5d13e7-f8c8-420a-b098-1eff13b9589b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 85.37%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_score = activation(model(X_test))\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0anPjHWAIqp",
    "outputId": "543efecd-adeb-41ce-da7e-d32713f5da43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(model, nn.Linear)\n",
    "assert isinstance(activation, nn.Sigmoid)\n",
    "assert isinstance(optimizer, torch.optim.SGD)\n",
    "assert isinstance(loss_fn, torch.nn.BCELoss)\n",
    "\n",
    "assert model.out_features == 1\n",
    "assert optimizer.param_groups[0][\"lr\"] == 1e-3\n",
    "\n",
    "assert 0.0 < loss.item() < 0.5\n",
    "assert 0.8 < auroc < 0.9\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALjv0UPkrjVJ"
   },
   "source": [
    "Jest to całkiem dobry wynik, a może być jeszcze lepszy. Sprawdźmy dla pewności jeszcze inne metryki: precyzję, recall oraz F1-score. Dodatkowo narysujemy krzywą precision-recall, czyli jak zmieniają się te metryki w zależności od przyjętego progu (threshold) prawdopodobieństwa, powyżej którego przyjmujemy klasę pozytywną. Taką krzywą należy rysować na zbiorze walidacyjnym, bo później chcemy wykorzystać tę informację do doboru progu, a nie chcemy mieć wycieku danych testowych (data leakage).\n",
    "\n",
    "Poniżej zaimplementowano także funkcję `get_optimal_threshold()`, która sprawdza, dla którego progu uzyskujemy maksymalny F1-score, i zwraca indeks oraz wartość optymalnego progu. Przyda ci się ona w dalszej części laboratorium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "DzdMu314rjVJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "def get_optimal_threshold(\n",
    "    precisions: np.array, recalls: np.array, thresholds: np.array\n",
    ") -> Tuple[int, float]:\n",
    "    numerator = 2 * precisions * recalls\n",
    "    denominator = precisions + recalls\n",
    "    f1_scores = np.divide(\n",
    "        numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0\n",
    "    )\n",
    "\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    return optimal_idx, optimal_threshold\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred_score) -> None:\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_score)\n",
    "    optimal_idx, optimal_threshold = get_optimal_threshold(\n",
    "        precisions, recalls, thresholds\n",
    "    )\n",
    "\n",
    "    disp = PrecisionRecallDisplay(precisions, recalls)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Precision-recall curve (opt. thresh.: {optimal_threshold:.4f})\")\n",
    "    plt.axvline(recalls[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.axhline(precisions[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "yGqMZZiYrjVJ",
    "outputId": "b50c747d-4bdc-40bb-db08-1ebf050e0ea2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid_score = activation(model(X_valid))\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfQPIUQ_LAs2"
   },
   "source": [
    "Jak widać, chociaż AUROC jest wysokie, to dla optymalnego F1-score recall nie jest zbyt wysoki, a precyzja jest już dość niska. Być może wynik uda się poprawić, używając modelu o większej pojemności - pełnej, głębokiej sieci neuronowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyW0GMjurjVK"
   },
   "source": [
    "## Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP298w6Cq7T6"
   },
   "source": [
    "Wszystko zaczęło się od inspirowanych biologią [sztucznych neuronów](https://en.wikipedia.org/wiki/Artificial_neuron), których próbowano użyć do symulacji mózgu. Naukowcy szybko odeszli od tego podejścia (sam problem modelowania okazał się też znacznie trudniejszy, niż sądzono), zamiast tego używając neuronów jako jednostek reprezentującą dowolną funkcję parametryczną $f(x, \\Theta)$. Każdy neuron jest zatem bardzo elastyczny, bo jedyne wymagania to funkcja różniczkowalna, a mamy do tego wektor parametrów $\\Theta$.\n",
    "\n",
    "W praktyce najczęściej można spotkać się z kilkoma rodzinami sieci neuronowych:\n",
    "1. Perceptrony wielowarstwowe (*MultiLayer Perceptron*, MLP) - najbardziej podobne do powyższego opisu, niezbędne do klasyfikacji i regresji\n",
    "2. Konwolucyjne (*Convolutional Neural Networks*, CNNs) - do przetwarzania danych z zależnościami przestrzennymi, np. obrazów czy dźwięku\n",
    "3. Rekurencyjne (*Recurrent Neural Networks*, RNNs) - do przetwarzania danych z zależnościami sekwencyjnymi, np. szeregi czasowe, oraz kiedyś do języka naturalnego\n",
    "4. Transformacyjne (*Transformers*), oparte o mechanizm atencji (*attention*) - do przetwarzania języka naturalnego (NLP), z którego wyparły RNNs, a coraz częściej także do wszelkich innych danych, np. obrazów, dźwięku\n",
    "5. Grafowe (*Graph Neural Networks*, GNNS) - do przetwarzania grafów\n",
    "\n",
    "Na tym laboratorium skupimy się na najprostszej architekturze, czyli MLP. Jest ona powszechnie łączona z wszelkimi innymi architekturami, bo pozwala dokonywać klasyfikacji i regresji. Przykładowo, klasyfikacja obrazów to zwykle CNN + MLP, klasyfikacja tekstów to transformer + MLP, a regresja na grafach to GNN + MLP.\n",
    "\n",
    "Dodatkowo, pomimo prostoty MLP są bardzo potężne - udowodniono, że perceptrony (ich powszechna nazwa) są [uniwersalnym aproksymatorem](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208), będącym w stanie przybliżyć dowolną funkcję z odpowiednio małym błędem, zakładając wystarczającą wielkość warstw sieci. Szczególne ich wersje potrafią nawet [reprezentować drzewa decyzyjne](https://www.youtube.com/watch?v=_okxGdHM5b8).\n",
    "\n",
    "Dla zainteresowanych polecamy [doskonałą książkę \"Dive into Deep Learning\", z implementacjami w PyTorchu](https://d2l.ai/chapter_multilayer-perceptrons/index.html), [klasyczną książkę \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/mlp.html), oraz [ten filmik](https://www.youtube.com/watch?v=BFHrIxKcLjA), jeśli zastanawiałeś/-aś się, czemu używamy deep learning, a nie naprzykład (wide?) learning. (aka. czemu staramy się budować głębokie sieci, a nie płytkie za to szerokie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ZjoGBU5upj"
   },
   "source": [
    "### Sieci MLP\n",
    "\n",
    "Dla przypomnienia, na wejściu mamy punkty ze zbioru treningowego, czyli $d$-wymiarowe wektory. W klasyfikacji chcemy znaleźć granicę decyzyjną, czyli krzywą, która oddzieli od siebie klasy. W wejściowej przestrzeni może być to trudne, bo chmury punktów z poszczególnych klas mogą być ze sobą dość pomieszane. Pamiętajmy też, że regresja logistyczna jest klasyfikatorem liniowym, czyli w danej przestrzeni potrafi oddzielić punkty tylko linią prostą.\n",
    "\n",
    "Sieć MLP składa się z warstw. Każda z nich dokonuje nieliniowego przekształcenia przestrzeni (można o tym myśleć jak o składaniu przestrzeni jakąś prostą/łamaną), tak, aby w finalnej przestrzeni nasze punkty były możliwie liniowo separowalne. Wtedy ostatnia warstwa z sigmoidą będzie potrafiła je rozdzielić od siebie.\n",
    "\n",
    "Poszczególne neurony składają się z iloczynu skalarnego wejść z wagami neuronu, oraz nieliniowej funkcji aktywacji. W PyTorchu są to osobne obiekty - `nn.Linear` oraz np. `nn.Sigmoid`. Funkcja aktywacji przyjmuje wynik iloczynu skalarnego i przekształca go, aby sprawdzić, jak mocno reaguje neuron na dane wejście. Musi być nieliniowa z dwóch powodów. Po pierwsze, tylko nieliniowe przekształcenia są na tyle potężne, żeby umożliwić liniową separację danych w ostatniej warstwie. Po drugie, liniowe przekształcenia zwyczajnie nie działają. Aby zrozumieć czemu, trzeba zobaczyć, co matematycznie oznacza sieć MLP.\n",
    "\n",
    "![perceptron](https://www.saedsayad.com/images/Perceptron_bkp_1.png)\n",
    "\n",
    "Zapisane matematycznie MLP to:\n",
    "\n",
    "$\\large\n",
    "h_1 = f_1(x) \\\\\n",
    "h_2 = f_2(h_1) \\\\\n",
    "h_3 = f_3(h_2) \\\\\n",
    "... \\\\\n",
    "h_n = f_n(h_{n-1})\n",
    "$\n",
    "\n",
    "gdzie $x$ to wejście $f_i$ to funkcja aktywacji $i$-tej warstwy, a $h_i$ to wyjście $i$-tej warstwy, nazywane **ukrytą reprezentacją (hidden representation)**, lub *latent representation*. Nazwa bierze się z tego, że w środku sieci wyciągamy cechy i wzorce w danych, które nie są widoczne na pierwszy rzut oka na wejściu.\n",
    "\n",
    "Załóżmy, że uczymy się na danych $x$ o jednym wymiarze (dla uproszczenia wzorów) oraz nie mamy funkcji aktywacji, czyli wykorzystujemy tak naprawdę aktywację liniową $f(x) = x$. Zobaczmy jak będą wyglądać dane przechodząc przez kolejne warstwy:\n",
    "\n",
    "$\\large\n",
    "h_1 = f_1(xw_1) = xw_1 \\\\\n",
    "h_2 = f_2(h_1w_2) = xw_1w_2 \\\\\n",
    "... \\\\\n",
    "h_n = f_n(h_{n-1}w_n) = xw_1w_2...w_n\n",
    "$\n",
    "\n",
    "gdzie $w_i$ to jest parametr $i$-tej warstwy sieci, $x$ to są dane (w naszym przypadku jedna liczba) wejściowa, a $h_i$ to wyjście $i$-tej warstwy.\n",
    "\n",
    "Jak widać, taka sieć o $n$ warstwach jest równoważna sieci o jednej warstwie z parametrem $w = w_1w_2...w_n$. Wynika to z tego, że złożenie funkcji liniowych jest także funkcją liniową - patrz notatki z algebry :)\n",
    "\n",
    "Jeżeli natomiast użyjemy nieliniowej funkcji aktywacji, często oznaczanej jako $\\sigma$, to wszystko będzie działać. Co ważne, ostatnia warstwa, dająca wyjście sieci, ma zwykle inną aktywację od warstw wewnątrz sieci, bo też ma inne zadanie - zwrócić wartość dla klasyfikacji lub regresji. Na wyjściu korzysta się z funkcji liniowej (regresja), sigmoidalnej (klasyfikacja binarna) lub softmax (klasyfikacja wieloklasowa).\n",
    "\n",
    "Wewnątrz sieci używano kiedyś sigmoidy oraz tangensa hiperbolicznego `tanh`, ale okazało się to nieefektywne przy uczeniu głębokich sieci o wielu warstwach. Nowoczesne sieci korzystają zwykle z funkcji ReLU (*rectified linear unit*), która jest zaskakująco prosta: $ReLU(x) = \\max(0, x)$. Okazało się, że bardzo dobrze nadaje się do treningu nawet bardzo głębokich sieci neuronowych. Nowsze funkcje aktywacji są głównie modyfikacjami ReLU.\n",
    "\n",
    "![relu](https://www.nomidl.com/wp-content/uploads/2022/04/image-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OUSefo_rjVL"
   },
   "source": [
    "### MLP w PyTorchu\n",
    "\n",
    "Warstwę neuronów w MLP nazywa się warstwą gęstą (*dense layer*) lub warstwą w pełni połączoną (*fully-connected layer*), i taki opis oznacza zwykle same neurony oraz funkcję aktywacji. PyTorch, jak już widzieliśmy, definiuje osobno transformację liniową oraz aktywację, a więc jedna warstwa składa się de facto z 2 obiektów, wywoływanych jeden po drugim. Inne frameworki, szczególnie wysokopoziomowe (np. Keras) łączą to często w jeden obiekt.\n",
    "\n",
    "MLP składa się zatem z sekwencji obiektów, które potem wywołuje się jeden po drugim, gdzie wyjście poprzedniego to wejście kolejnego. Ale nie można tutaj używać Pythonowych list! Z perspektywy PyTorcha to wtedy niezależne obiekty i nie zostanie wtedy przekazany między nimi gradient. Trzeba tutaj skorzystać z `nn.Sequential`, aby tworzyć taki pipeline.\n",
    "\n",
    "Rozmiary wejścia i wyjścia dla każdej warstwy trzeba w PyTorchu podawać explicite. Jest to po pierwsze edukacyjne, a po drugie często ułatwia wnioskowanie o działaniu sieci oraz jej debugowanie - mamy jasno podane, czego oczekujemy. Niektóre frameworki (np. Keras) obliczają to automatycznie.\n",
    "\n",
    "Co ważne, ostatnia warstwa zwykle nie ma funkcji aktywacji. Wynika to z tego, że obliczanie wielu funkcji kosztu (np. entropii krzyżowej) na aktywacjach jest często niestabilne numerycznie. Z tego powodu PyTorch oferuje funkcje kosztu zawierające w środku aktywację dla ostatniej warstwy, a ich implementacje są stabilne numerycznie. Przykładowo, `nn.BCELoss` przyjmuje wejście z zaaplikowanymi już aktywacjami, ale może skutkować under/overflow, natomiast `nn.BCEWithLogitsLoss` przyjmuje wejście bez aktywacji, a w środku ma specjalną implementację łączącą binarną entropię krzyżową z aktywacją sigmoidalną. Oczywiście w związku z tym aby dokonać potem predykcji w praktyce, trzeba pamiętać o użyciu funkcji aktywacji. Często korzysta się przy tym z funkcji z modułu `torch.nn.functional`, które są w tym wypadku nieco wygodniejsze od klas wywoływalnych z `torch.nn`.\n",
    "\n",
    "Całe sieci w PyTorchu tworzy się jako klasy dziedziczące po `nn.Module`. Co ważne, obiekty, z których tworzymy sieć, np. `nn.Linear`, także dziedziczą po tej klasie. Pozwala to na bardzo modułową budowę kodu, zgodną z zasadami OOP. W konstruktorze najpierw trzeba zawsze wywołać konstruktor rodzica - `super().__init__()`, a później tworzy się potrzebne obiekty i zapisuje jako atrybuty. Każdy atrybut dziedziczący po `nn.Module` lub `nn.Parameter` jest uważany za taki, który zawiera parametry sieci, a więc przy wywołaniu metody `parameters()` - parametry z tych atrybutów pojawią się w liście wszystkich parametrów. Musimy też zdefiniować metodę `forward()`, która przyjmuje tensor `x` i zwraca wynik. Typowo ta metoda po prostu używa obiektów zdefiniowanych w konstruktorze.\n",
    "\n",
    "\n",
    "**UWAGA: nigdy w normalnych warunkach się nie woła metody `forward` ręcznie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8niDgExAMDO"
   },
   "source": [
    "#### Zadanie 4 (0.5 punktu)\n",
    "\n",
    "Uzupełnij implementację 3-warstwowej sieci MLP. Użyj rozmiarów:\n",
    "* pierwsza warstwa: input_size x 256\n",
    "* druga warstwa: 256 x 128\n",
    "* trzecia warstwa: 128 x 1\n",
    "\n",
    "Użyj funkcji aktywacji ReLU.\n",
    "\n",
    "Przydatne klasy:\n",
    "- `nn.Sequential`\n",
    "- `nn.Linear`\n",
    "- `nn.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "WHPyDSrArjVM"
   },
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x, threshold: float = 0.5):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return (y_pred_score > threshold).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-dSVSAxrjVM",
    "outputId": "f50de5ec-a423-4dfb-f6cf-0636ab001f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6781\n",
      "Epoch 200 train loss: 0.6581\n",
      "Epoch 400 train loss: 0.6410\n",
      "Epoch 600 train loss: 0.6263\n",
      "Epoch 800 train loss: 0.6134\n",
      "Epoch 1000 train loss: 0.6021\n",
      "Epoch 1200 train loss: 0.5920\n",
      "Epoch 1400 train loss: 0.5831\n",
      "Epoch 1600 train loss: 0.5751\n",
      "Epoch 1800 train loss: 0.5678\n",
      "final loss: 0.5613\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = MLP(input_size=X_train.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "num_epochs = 2000\n",
    "evaluation_steps = 200\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % evaluation_steps == 0:\n",
    "        print(f\"Epoch {i} train loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "LP5GSup24dXU",
    "outputId": "a807ab2f-3db2-4b3f-d64e-41c3876553d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 79.14%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # positive class probabilities\n",
    "    y_pred_valid_score = model.predict_proba(X_valid)\n",
    "    y_pred_test_score = model.predict_proba(X_test)\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_test_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6QJZNk2CAvn",
    "outputId": "ba66b885-92bc-426e-a1c6-f07de5cbca7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == X_train.shape[1]\n",
    "    and module.out_features == 256\n",
    "    for module in model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 256\n",
    "    and module.out_features == 128\n",
    "    for module in model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 128\n",
    "    and module.out_features == 1\n",
    "    for module in model.modules()\n",
    ")\n",
    "\n",
    "assert any(isinstance(module, nn.ReLU) for module in model.modules())\n",
    "\n",
    "assert 0.5 < loss.item() < 0.6\n",
    "assert 0.6 < auroc < 0.9\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoAu7rC8rjVN"
   },
   "source": [
    "AUROC jest podobne, a precision i recall spadły - wypadamy wręcz gorzej od regresji liniowej! Skoro dodaliśmy więcej warstw, to może pojemność modelu jest teraz za duża i trzeba by go zregularyzować?\n",
    "\n",
    "Sieci neuronowe bardzo łatwo przeuczają, bo są bardzo elastycznymi i pojemnymi modelami. Dlatego mają wiele różnych rodzajów regularyzacji, których używa się razem. Co ciekawe, udowodniono eksperymentalnie, że zbyt duże sieci z mocną regularyzacją działają lepiej niż mniejsze sieci, odpowiedniego rozmiaru, za to ze słabszą regularyzacją.\n",
    "\n",
    "Pierwszy rodzaj regularyzacji to znana nam już **regularyzacja L2**, czyli penalizacja zbyt dużych wag. W kontekście sieci neuronowych nazywa się też ją czasem *weight decay*. W PyTorchu dodaje się ją jako argument do optymalizatora.\n",
    "\n",
    "Regularyzacja specyficzna dla sieci neuronowych to **dropout**. Polega on na losowym wyłączaniu zadanego procenta neuronów podczas treningu. Pomimo prostoty okazała się niesamowicie skuteczna, szczególnie w treningu bardzo głębokich sieci. Co ważne, jest to mechanizm używany tylko podczas treningu - w trakcie predykcji za pomocą sieci wyłącza się ten mechanizm i dokonuje normalnie predykcji całą siecią. Podejście to można potraktować jak ensemble learning, podobny do lasów losowych - wyłączając losowe części sieci, w każdej iteracji trenujemy nieco inną sieć, co odpowiada uśrednianiu predykcji różnych algorytmów. Typowo stosuje się dość mocny dropout, rzędu 25-50%. W PyTorchu implementuje go warstwa `nn.Dropout`, aplikowana zazwyczaj po funkcji aktywacji.\n",
    "\n",
    "Ostatni, a być może najważniejszy rodzaj regularyzacji to **wczesny stop (early stopping)**. W każdym kroku mocniej dostosowujemy terenową sieć do zbioru treningowego, a więc zbyt długi trening będzie skutkował przeuczeniem. W metodzie wczesnego stopu używamy wydzielonego zbioru walidacyjnego (pojedynczego, metoda holdout), sprawdzając co określoną liczbę epok wynik na tym zbiorze. Jeżeli nie uzyskamy wyniku lepszego od najlepszego dotychczas uzyskanego przez określoną liczbę epok, to przerywamy trening. Okres, przez który czekamy na uzyskanie lepszego wyniku, to cierpliwość (*patience*). Im mniejsze, tym mocniejszy jest ten rodzaj regularyzacji, ale trzeba z tym uważać, bo łatwo jest przesadzić i zbyt szybko przerywać trening. Niektóre implementacje uwzględniają tzw. *grace period*, czyli gwarantowaną minimalną liczbę epok, przez którą będziemy trenować sieć, niezależnie od wybranej cierpliwości.\n",
    "\n",
    "Dodatkowo ryzyko przeuczenia można zmniejszyć, używając mniejszej stałej uczącej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MJCnL21rjVN"
   },
   "source": [
    "#### Zadanie 5 (1.5 punktu)\n",
    "\n",
    "Zaimplementuj funkcję `evaluate_model()`, obliczającą metryki na zbiorze testowym:\n",
    "- wartość funkcji kosztu (loss)\n",
    "- AUROC\n",
    "- optymalny próg\n",
    "- F1-score przy optymalnym progu\n",
    "- precyzję oraz recall dla optymalnego progu\n",
    "\n",
    "Jeżeli podana jest wartość argumentu `threshold`, to użyj jej do zamiany prawdopodobieństw na twarde predykcje. W przeciwnym razie użyj funkcji `get_optimal_threshold` i oblicz optymalną wartość progu.\n",
    "\n",
    "Pamiętaj o przełączeniu modelu w tryb ewaluacji oraz o wyłączeniu obliczania gradientów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ji_C7PhlrjVN"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    X: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    loss_fn: nn.Module,\n",
    "    threshold: Optional[float] = None,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X)\n",
    "        y_proba = model.predict_proba(X)\n",
    "\n",
    "        if threshold is None:\n",
    "            precisions, recalls, thresholds = precision_recall_curve(y, y_proba)\n",
    "            _, threshold = get_optimal_threshold(precisions, recalls, thresholds)\n",
    "\n",
    "        y_proba_threshold = (y_proba > threshold).to(torch.float)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        precision = precision_score(y, y_proba_threshold)\n",
    "        recall = recall_score(y, y_proba_threshold)\n",
    "        f1 = f1_score(y, y_proba_threshold)\n",
    "        auroc = roc_auc_score(y, y_proba_threshold)\n",
    "\n",
    "    result = {\n",
    "        \"loss\": loss.item(),\n",
    "        \"AUROC\": auroc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"threshold\": threshold,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbFt4TPCFaQn",
    "outputId": "539e41fc-68f5-4a98-e9e1-b96ec7105daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate_model(model, X_train, y_train, loss_fn)\n",
    "\n",
    "assert 0.5 < eval_result[\"loss\"] < 0.6\n",
    "assert 0.6 < eval_result[\"AUROC\"] < 0.9\n",
    "assert 0.3 < eval_result[\"precision\"] < 0.6\n",
    "assert 0.6 < eval_result[\"recall\"] < 0.9\n",
    "assert 0.4 < eval_result[\"F1-score\"] < 0.7\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObP4EcuXrjVN"
   },
   "source": [
    "#### Zadanie 6 (0.5 punktu)\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP z dropout (50%). Rozmiary warstw ukrytych mają wynosić 256 i 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Tfh-sveRrjVO"
   },
   "outputs": [],
   "source": [
    "class RegularizedMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x, threshold: float = 0.5):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return (y_pred_score > threshold).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCkuNtIAJTep",
    "outputId": "c96cfcc0-820e-4e0b-d23e-94bfd929f221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "verification_input_size = 143\n",
    "verification_dropout_p = 0.125\n",
    "verification_model = RegularizedMLP(\n",
    "    input_size=verification_input_size,\n",
    "    dropout_p=verification_dropout_p,\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == verification_input_size\n",
    "    and module.out_features == 256\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 256\n",
    "    and module.out_features == 128\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 128\n",
    "    and module.out_features == 1\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Dropout) and module.p == verification_dropout_p\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "assert any(isinstance(module, nn.ReLU) for module in verification_model.modules())\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEk9azaULAsz"
   },
   "source": [
    "Opisaliśmy wcześniej podstawowy optymalizator w sieciach neuronowych - spadek wzdłuż gradientu. Jednak wymaga on użycia całego zbioru danych, aby obliczyć gradient, co jest często niewykonalne przez rozmiar zbioru. Dlatego wymyślono **stochastyczny spadek wzdłuż gradientu (stochastic gradient descent, SGD)**, w którym używamy 1 przykładu naraz, liczymy gradient tylko po nim i aktualizujemy parametry. Jest to oczywiście dość grube przybliżenie gradientu, ale pozwala robić szybko dużo małych kroków. Kompromisem, którego używa się w praktyce, jest **minibatch gradient descent**, czyli używanie batchy np. 32, 64 czy 128 przykładów.\n",
    "\n",
    "Rzadko wspominanym, a ważnym faktem jest także to, że stochastyczność metody optymalizacji jest sama w sobie też [metodą regularyzacji](https://arxiv.org/abs/2101.12176), a więc `batch_size` to także hiperparametr.\n",
    "\n",
    "Obecnie najpopularniejszą odmianą SGD jest [Adam](https://arxiv.org/abs/1412.6980), gdyż uczy on szybko sieć oraz daje bardzo dobre wyniki nawet przy niekoniecznie idealnie dobranych hiperparametrach. W PyTorchu najlepiej korzystać z jego implementacji `AdamW`, która jest nieco lepsza niż implementacja `Adam`. Jest to zasadniczo zawsze wybór domyślny przy treningu współczesnych sieci neuronowych.\n",
    "\n",
    "Na razie użyjemy jednak minibatch SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N3GKrWirjVO"
   },
   "source": [
    "Poniżej znajduje się implementacja prostej klasy dziedziczącej po `Dataset` - tak w PyTorchu implementuje się własne zbiory danych. Użycie takich klas umożliwia użycie klas ładujących dane (`DataLoader`), które z kolei pozwalają łatwo ładować batche danych. Trzeba w takiej klasie zaimplementować metody:\n",
    "- `__len__` - zwraca ilość punktów w zbiorze\n",
    "- `__getitem__` - zwraca przykład ze zbioru pod danym indeksem oraz jego klasę\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ZR2pWn8vrjVP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrBS3j2CrjVP"
   },
   "source": [
    "#### Zadanie 7 (1.5 punktu)\n",
    "\n",
    "Zaimplementuj pętlę treningowo-walidacyjną dla sieci neuronowej. Wykorzystaj podane wartości hiperparametrów do treningu (stała ucząca, prawdopodobieństwo dropoutu, regularyzacja L2, rozmiar batcha, maksymalna liczba epok). Użyj optymalizatora SGD.\n",
    "\n",
    "Dodatkowo zaimplementuj regularyzację przez early stopping. Sprawdzaj co epokę wynik na zbiorze walidacyjnym. Użyj podanej wartości patience, a jako metryki po prostu wartości funkcji kosztu. Może się tutaj przydać zaimplementowana funkcja `evaluate_model()`.\n",
    "\n",
    "Pamiętaj o tym, aby przechowywać najlepszy dotychczasowy wynik walidacyjny oraz najlepszy dotychczasowy model. Zapamiętaj też optymalny próg do klasyfikacji dla najlepszego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "JRf5P88frjVP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntinmT_prjVP",
    "outputId": "fe3e6f56-ea3b-4626-dafe-648468b73328",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6952, eval loss 0.6951975226402283\n",
      "Epoch 20 train loss: 0.5249, eval loss 0.5209187269210815\n",
      "Epoch 40 train loss: 0.4619, eval loss 0.45202168822288513\n",
      "Epoch 60 train loss: 0.4210, eval loss 0.39824753999710083\n",
      "Epoch 80 train loss: 0.4136, eval loss 0.3692069947719574\n",
      "Epoch 100 train loss: 0.3711, eval loss 0.35648438334465027\n",
      "Epoch 120 train loss: 0.3913, eval loss 0.3499107360839844\n",
      "Epoch 140 train loss: 0.3949, eval loss 0.3453883230686188\n",
      "Epoch 160 train loss: 0.3834, eval loss 0.34168127179145813\n",
      "Epoch 180 train loss: 0.3722, eval loss 0.3385331630706787\n",
      "Epoch 200 train loss: 0.3594, eval loss 0.33575084805488586\n",
      "Epoch 220 train loss: 0.3512, eval loss 0.33329129219055176\n",
      "Epoch 240 train loss: 0.3766, eval loss 0.3311932384967804\n",
      "Epoch 260 train loss: 0.3569, eval loss 0.32933783531188965\n",
      "Epoch 280 train loss: 0.3564, eval loss 0.3277125656604767\n"
     ]
    }
   ],
   "source": [
    "model = RegularizedMLP(input_size=X_train.shape[1], dropout_p=dropout_p)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    val_loss = valid_metrics[\"loss\"]\n",
    "\n",
    "    if epoch_num % 20 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\"\n",
    "        )\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        best_threshold = valid_metrics[\"threshold\"]\n",
    "        steps_without_improvement = 0\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        if steps_without_improvement >= early_stopping_patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmSddl-rrjVP",
    "outputId": "4df081b5-2020-497f-fae2-7722e946a849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 81.23%\n",
      "F1: 68.73%\n",
      "Precision: 61.43%\n",
      "Recall: 78.00%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {test_metrics['AUROC']:.2%}\")\n",
    "print(f\"F1: {test_metrics['F1-score']:.2%}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.2%}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLBNX5zTKKe_",
    "outputId": "3f295f60-c7e4-46ad-d17d-ca3f1e3185c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "assert test_metrics[\"AUROC\"] > 0.8\n",
    "assert test_metrics[\"F1-score\"] > 0.6\n",
    "assert test_metrics[\"precision\"] > 0.5\n",
    "assert test_metrics[\"recall\"] > 0.6\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn_jVnX7rjVQ"
   },
   "source": [
    "Wyniki wyglądają już dużo lepiej.\n",
    "\n",
    "Na koniec laboratorium dołożymy do naszego modelu jeszcze 3 powrzechnie używane techniki, które są bardzo proste, a pozwalają często ulepszyć wynik modelu.\n",
    "\n",
    "Pierwszą z nich są **warstwy normalizacji (normalization layers)**. Powstały one początkowo z założeniem, że przez przekształcenia przestrzeni dokonywane przez sieć zmienia się rozkład prawdopodobieństw pomiędzy warstwami, czyli tzw. *internal covariate shift*. Później okazało się, że zastosowanie takiej normalizacji wygładza powierzchnię funkcji kosztu, co ułatwia i przyspiesza optymalizację. Najpowszechniej używaną normalizacją jest **batch normalization (batch norm)**.\n",
    "\n",
    "Drugim ulepszeniem jest dodanie **wag klas (class weights)**. Mamy do czynienia z problemem klasyfikacji niezbalansowanej, więc klasa mniejszościowa, ważniejsza dla nas, powinna dostać większą wagę. Implementuje się to trywialnie prosto - po prostu mnożymy wartość funkcji kosztu dla danego przykładu przez wagę dla prawdziwej klasy tego przykładu. Praktycznie każdy klasyfikator operujący na jakiejś ważonej funkcji może działać w ten sposób, nie tylko sieci neuronowe.\n",
    "\n",
    "Ostatnim ulepszeniem jest zamiana SGD na optymalizator Adam, a konkretnie na optymalizator `AdamW`. Jest to przykład **optymalizatora adaptacyjnego (adaptive optimizer)**, który potrafi zaadaptować stałą uczącą dla każdego parametru z osobna w trakcie treningu. Wykorzystuje do tego gradienty - w uproszczeniu, im większa wariancja gradientu, tym mniejsze kroki w tym kierunku robimy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am5zTrKWrjVQ"
   },
   "source": [
    "#### Zadanie 8 (0.5 punktu)\n",
    "\n",
    "Zaimplementuj model `NormalizingMLP`, o takiej samej strukturze jak `RegularizedMLP`, ale dodatkowo z warstwami `BatchNorm1d` pomiędzy warstwami `Linear` oraz `ReLU`.\n",
    "\n",
    "Za pomocą funkcji `compute_class_weight()` oblicz wagi dla poszczególnych klas. Użyj opcji `\"balanced\"`. Przekaż do funkcji kosztu wagę klasy pozytywnej (pamiętaj, aby zamienić ją na tensor).\n",
    "\n",
    "Zamień używany optymalizator na `AdamW`.\n",
    "\n",
    "Na koniec skopiuj resztę kodu do treningu z poprzedniego zadania, wytrenuj sieć i oblicz wyniki na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "5CwegjoGrjVQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "class NormalizingMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x, threshold: float = 0.5):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return (y_pred_score > threshold).to(torch.int32)\n",
    "\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train.numpy().reshape(-1)),\n",
    "    y=y_train.numpy().reshape(-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "J78C1wHdrjVQ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnqnRI97rjVR",
    "outputId": "f42a9f47-c533-4169-ba11-71969281fb48",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.5883, eval loss 0.48024284839630127\n",
      "Epoch 1 train loss: 0.6050, eval loss 0.47324424982070923\n",
      "Epoch 2 train loss: 0.5866, eval loss 0.4727935492992401\n",
      "Epoch 3 train loss: 0.5351, eval loss 0.47200095653533936\n",
      "Epoch 4 train loss: 0.6066, eval loss 0.4728669822216034\n",
      "Epoch 5 train loss: 0.5138, eval loss 0.47225236892700195\n",
      "Epoch 6 train loss: 0.5708, eval loss 0.47217950224876404\n",
      "Epoch 7 train loss: 0.6019, eval loss 0.4714297354221344\n",
      "Epoch 8 train loss: 0.5226, eval loss 0.473087877035141\n",
      "Epoch 9 train loss: 0.5002, eval loss 0.4744650423526764\n",
      "Epoch 10 train loss: 0.5468, eval loss 0.4744870662689209\n",
      "Epoch 11 train loss: 0.5797, eval loss 0.4747643768787384\n"
     ]
    }
   ],
   "source": [
    "model = NormalizingMLP(input_size=X_train.shape[1], dropout_p=dropout_p)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1])\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    val_loss = valid_metrics[\"loss\"]\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\"\n",
    "    )\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        best_threshold = valid_metrics[\"threshold\"]\n",
    "        steps_without_improvement = 0\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        if steps_without_improvement >= early_stopping_patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cJipdTdrjVR",
    "outputId": "716b78f1-e542-4bda-bdd1-116dd3d049df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 82.06%\n",
      "F1: 69.88%\n",
      "Precision: 62.55%\n",
      "Recall: 79.15%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")\n",
    "print(f\"Precision: {100 * test_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {100 * test_metrics['recall']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6573eO9YMi1B",
    "outputId": "b2439df0-054c-4786-d97e-4dcdf9734ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is correct!\n"
     ]
    }
   ],
   "source": [
    "verification_input_size = 143\n",
    "verification_dropout_p = 0.125\n",
    "verification_model = NormalizingMLP(\n",
    "    input_size=verification_input_size,\n",
    "    dropout_p=verification_dropout_p,\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == verification_input_size\n",
    "    and module.out_features == 256\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 256\n",
    "    and module.out_features == 128\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Linear)\n",
    "    and module.in_features == 128\n",
    "    and module.out_features == 1\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.Dropout) and module.p == verification_dropout_p\n",
    "    for module in verification_model.modules()\n",
    ")\n",
    "assert any(isinstance(module, nn.ReLU) for module in verification_model.modules())\n",
    "\n",
    "assert any(\n",
    "    isinstance(module, nn.BatchNorm1d) for module in verification_model.modules()\n",
    ")\n",
    "\n",
    "assert test_metrics[\"AUROC\"] > 0.8\n",
    "assert test_metrics[\"F1-score\"] > 0.6\n",
    "assert test_metrics[\"precision\"] > 0.5\n",
    "assert test_metrics[\"recall\"] > 0.6\n",
    "\n",
    "print(\"Solution is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyoRnHT4GFR9"
   },
   "source": [
    "## Akceleracja sprzętowa (dla zainteresowanych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8aAct2jrjVR"
   },
   "source": [
    "Jak wcześniej wspominaliśmy, użycie akceleracji sprzętowej, czyli po prostu GPU do obliczeń, jest bardzo efektywne w przypadku sieci neuronowych. Karty graficzne bardzo efektywnie mnożą macierze, a sieci neuronowe to, jak można było się przekonać, dużo mnożenia macierzy.\n",
    "\n",
    "W PyTorchu jest to dosyć łatwe, ale trzeba robić to explicite. Służy do tego metoda `.to()`, która przenosi tensory między CPU i GPU. Poniżej przykład, jak to się robi (oczywiście trzeba mieć skonfigurowane GPU, żeby działało):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66-FM1DCrjVS",
    "outputId": "bec3eb1b-e857-4a8c-cc69-e54b96b5c4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.9548, time: 0.7520015239715576\n",
      "Epoch 1 train loss: 0.4061, time: 0.7041518688201904\n",
      "Epoch 2 train loss: 0.4791, time: 0.6975264549255371\n",
      "Epoch 3 train loss: 0.4161, time: 0.7107326984405518\n",
      "Epoch 4 train loss: 0.6556, time: 0.7050693035125732\n",
      "Epoch 6 train loss: 0.3117, time: 0.959007740020752\n",
      "Epoch 7 train loss: 0.4089, time: 0.9975550174713135\n",
      "Epoch 8 train loss: 0.4781, time: 0.8997926712036133\n",
      "Epoch 9 train loss: 0.4094, time: 0.7060062885284424\n",
      "Epoch 11 train loss: 0.4756, time: 0.7000505924224854\n",
      "Epoch 12 train loss: 0.3890, time: 0.6925191879272461\n",
      "Epoch 13 train loss: 0.5012, time: 0.7031698226928711\n",
      "Epoch 14 train loss: 0.3786, time: 0.7332885265350342\n",
      "Epoch 15 train loss: 0.4223, time: 0.7007851600646973\n",
      "Epoch 17 train loss: 0.3381, time: 0.9261741638183594\n",
      "Epoch 18 train loss: 0.4378, time: 0.9620780944824219\n",
      "Epoch 19 train loss: 0.5017, time: 0.9886977672576904\n",
      "Epoch 20 train loss: 0.4145, time: 0.70090651512146\n",
      "Epoch 22 train loss: 0.4962, time: 0.7213594913482666\n",
      "Epoch 23 train loss: 0.4098, time: 0.694066047668457\n",
      "Epoch 24 train loss: 0.3631, time: 0.810701847076416\n",
      "Epoch 25 train loss: 0.4535, time: 0.9213027954101562\n",
      "Epoch 26 train loss: 0.4510, time: 1.0049800872802734\n",
      "Epoch 28 train loss: 0.5909, time: 0.8402836322784424\n",
      "Epoch 29 train loss: 0.5243, time: 0.6982309818267822\n",
      "AUROC: 81.61%\n",
      "F1: 69.62%\n",
      "{'loss': 0.511533260345459, 'AUROC': 0.8160665277233239, 'precision': 0.6316883116883117, 'recall': 0.7755102040816326, 'F1-score': 0.6962496421414257, 'threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class CudaMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x, threshold: float = 0.5):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return (y_pred_score > threshold).to(torch.int32)\n",
    "\n",
    "\n",
    "model = CudaMLP(X_train.shape[1]).to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1].to(\"cuda\"))\n",
    "\n",
    "step_counter = 0\n",
    "time_from_eval = time.time()\n",
    "for epoch_id in range(30):\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to(\"cuda\")\n",
    "        batch_y = batch_y.to(\"cuda\")\n",
    "\n",
    "        loss = loss_fn(model(batch_x), batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step_counter % evaluation_steps == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch_id} train loss: {loss.item():.4f}, time: {time.time() - time_from_eval}\"\n",
    "            )\n",
    "            time_from_eval = time.time()\n",
    "\n",
    "        step_counter += 1\n",
    "\n",
    "test_res = evaluate_model(\n",
    "    model.to(\"cpu\"), X_test, y_test, loss_fn.to(\"cpu\"), threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"AUROC: {test_res['AUROC']:.2%}\")\n",
    "print(f\"F1: {test_res['F1-score']:.2%}\")\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOda03FhrjVS"
   },
   "source": [
    "Co prawda ten model nie będzie tak dobry jak ten z laboratorium, ale zwróć uwagę, o ile jest większy, a przy tym szybszy.\n",
    "\n",
    "Dla zainteresowanych polecamy [tę serie artykułów](https://medium.com/@adi.fu7/ai-accelerators-part-i-intro-822c2cdb4ca4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONuk--Z3rjVS"
   },
   "source": [
    "## Zadanie dla chętnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GrWeHTvrjVS"
   },
   "source": [
    "Jak widzieliśmy, sieci neuronowe mają bardzo dużo hiperparametrów. Przeszukiwanie ich grid search'em jest więc niewykonalne, a chociaż random search by działał, to potrzebowałby wielu iteracji, co też jest kosztowne obliczeniowo.\n",
    "\n",
    "Zaimplementuj inteligentne przeszukiwanie przestrzeni hiperparametrów za pomocą biblioteki [Optuna](https://optuna.org/). Implementuje ona między innymi algorytm Tree Parzen Estimator (TPE), należący do grupy algorytmów typu Bayesian search. Typowo osiągają one bardzo dobre wyniki, a właściwie zawsze lepsze od przeszukiwania losowego. Do tego wystarcza im często niewielka liczba kroków.\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP, gdzie pierwsza warstwa ma rozmiar ukryty N, a druga N // 2. Ucz ją optymalizatorem Adam przez maksymalnie 300 epok z cierpliwością 10.\n",
    "\n",
    "Przeszukaj wybrane zakresy dla hiperparametrów:\n",
    "- rozmiar warstw ukrytych (N)\n",
    "- stała ucząca\n",
    "- batch size\n",
    "- siła regularyzacji L2\n",
    "- prawdopodobieństwo dropoutu\n",
    "\n",
    "Wykorzystaj przynajmniej 30 iteracji. Następnie przełącz algorytm na losowy (Optuna także jego implementuje), wykonaj 30 iteracji i porównaj jakość wyników.\n",
    "\n",
    "Przydatne materiały:\n",
    "- [Optuna code examples - PyTorch](https://optuna.org/#code_examples)\n",
    "- [Auto-Tuning Hyperparameters with Optuna and PyTorch](https://www.youtube.com/watch?v=P6NwZVl8ttc)\n",
    "- [Hyperparameter Tuning of Neural Networks with Optuna and PyTorch](https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837)\n",
    "- [Using Optuna to Optimize PyTorch Hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcnrIUJTYk8s",
    "outputId": "e479c2a5-ec31-4f3e-c3f1-e7f9974fa5bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtkvv0rpXVob",
    "outputId": "f16278e9-45fe-40bc-9f99-abab14ff2112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-27 16:36:06,943] A new study created in memory with name: no-name-2f77022b-e76e-40d4-899c-5c32a4fbe0f3\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:36:15,971] Trial 0 finished with value: 0.4826052188873291 and parameters: {'lr': 0.0335105981110847, 'batch_size': 64, 'l2_reg': 0.05259566016466677, 'layers_size': 448, 'dropout_p': 0.4559551847473908}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:36:20,645] Trial 1 finished with value: 0.488445520401001 and parameters: {'lr': 0.0364452092558437, 'batch_size': 96, 'l2_reg': 0.08213194711185891, 'layers_size': 128, 'dropout_p': 0.6572406742048438}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:36:44,578] Trial 2 finished with value: 0.5017747282981873 and parameters: {'lr': 0.0436488209093034, 'batch_size': 16, 'l2_reg': 0.022284301060702838, 'layers_size': 192, 'dropout_p': 0.5031847299626583}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:36:48,050] Trial 3 finished with value: 0.4839304983615875 and parameters: {'lr': 0.03709963678188517, 'batch_size': 112, 'l2_reg': 0.09131625233748993, 'layers_size': 128, 'dropout_p': 0.39191658198723756}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:36:54,858] Trial 4 finished with value: 0.5028019547462463 and parameters: {'lr': 0.07595686770457313, 'batch_size': 48, 'l2_reg': 0.0637766371577932, 'layers_size': 384, 'dropout_p': 0.5517134411323177}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:37:00,239] Trial 5 finished with value: 0.4912720322608948 and parameters: {'lr': 0.06907038166749847, 'batch_size': 64, 'l2_reg': 0.024063189752195815, 'layers_size': 128, 'dropout_p': 0.504761403879235}. Best is trial 0 with value: 0.4826052188873291.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:37:13,029] Trial 6 finished with value: 0.4762137532234192 and parameters: {'lr': 0.022732507186066543, 'batch_size': 32, 'l2_reg': 0.009199064309246075, 'layers_size': 256, 'dropout_p': 0.6438640433526317}. Best is trial 6 with value: 0.4762137532234192.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:37:43,390] Trial 7 finished with value: 0.49152737855911255 and parameters: {'lr': 0.02369467671590445, 'batch_size': 16, 'l2_reg': 0.03037560799340686, 'layers_size': 320, 'dropout_p': 0.44063201602123336}. Best is trial 6 with value: 0.4762137532234192.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:37:52,119] Trial 8 finished with value: 0.48445266485214233 and parameters: {'lr': 0.09300249884441723, 'batch_size': 64, 'l2_reg': 0.016477505927704857, 'layers_size': 320, 'dropout_p': 0.39864805764537725}. Best is trial 6 with value: 0.4762137532234192.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:01,946] Trial 9 finished with value: 0.5054211616516113 and parameters: {'lr': 0.09775169510455038, 'batch_size': 32, 'l2_reg': 0.004367170444890904, 'layers_size': 192, 'dropout_p': 0.5340127720061877}. Best is trial 6 with value: 0.4762137532234192.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:05,606] Trial 10 finished with value: 0.46860164403915405 and parameters: {'lr': 0.002103683795015736, 'batch_size': 128, 'l2_reg': 0.04061138429041272, 'layers_size': 512, 'dropout_p': 0.25096321400276056}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:10,541] Trial 11 finished with value: 0.47007322311401367 and parameters: {'lr': 0.000535946206017346, 'batch_size': 128, 'l2_reg': 0.043265502969614664, 'layers_size': 512, 'dropout_p': 0.2414459222461515}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:14,294] Trial 12 finished with value: 0.47458794713020325 and parameters: {'lr': 0.002520345868976856, 'batch_size': 128, 'l2_reg': 0.04178232004340428, 'layers_size': 512, 'dropout_p': 0.23448190416481052}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:19,256] Trial 13 finished with value: 0.47217947244644165 and parameters: {'lr': 0.0027378004137404016, 'batch_size': 128, 'l2_reg': 0.06514227813265876, 'layers_size': 512, 'dropout_p': 0.21458449928098894}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:24,323] Trial 14 finished with value: 0.4746634364128113 and parameters: {'lr': 0.013062054909881708, 'batch_size': 96, 'l2_reg': 0.04130147906473885, 'layers_size': 448, 'dropout_p': 0.3061598195663868}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:30,160] Trial 15 finished with value: 0.4816792905330658 and parameters: {'lr': 0.05860312198075827, 'batch_size': 96, 'l2_reg': 0.05574284744612555, 'layers_size': 448, 'dropout_p': 0.3430786872712227}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:35,078] Trial 16 finished with value: 0.47272777557373047 and parameters: {'lr': 0.015813028603714925, 'batch_size': 112, 'l2_reg': 0.036858524943071375, 'layers_size': 512, 'dropout_p': 0.2889084992729355}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:39,781] Trial 17 finished with value: 0.47039079666137695 and parameters: {'lr': 0.0010843426576647322, 'batch_size': 128, 'l2_reg': 0.06564622464197055, 'layers_size': 384, 'dropout_p': 0.2642606451636109}. Best is trial 10 with value: 0.46860164403915405.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:45,570] Trial 18 finished with value: 0.46596238017082214 and parameters: {'lr': 0.011731233810189203, 'batch_size': 112, 'l2_reg': 0.0769591382325227, 'layers_size': 384, 'dropout_p': 0.20116368234441523}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:50,875] Trial 19 finished with value: 0.47332051396369934 and parameters: {'lr': 0.015519834263278666, 'batch_size': 112, 'l2_reg': 0.08195871624085738, 'layers_size': 384, 'dropout_p': 0.3518555722631351}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:38:58,937] Trial 20 finished with value: 0.4814131259918213 and parameters: {'lr': 0.026324602236166793, 'batch_size': 80, 'l2_reg': 0.09866710300493423, 'layers_size': 448, 'dropout_p': 0.20044077742573077}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:03,733] Trial 21 finished with value: 0.46739664673805237 and parameters: {'lr': 0.011387066743592288, 'batch_size': 128, 'l2_reg': 0.0740673338408865, 'layers_size': 512, 'dropout_p': 0.2581587469669244}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:09,151] Trial 22 finished with value: 0.4768844246864319 and parameters: {'lr': 0.011379074712946363, 'batch_size': 112, 'l2_reg': 0.07715329744176866, 'layers_size': 384, 'dropout_p': 0.3030320922158868}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:14,484] Trial 23 finished with value: 0.47284555435180664 and parameters: {'lr': 0.009186014894763894, 'batch_size': 128, 'l2_reg': 0.0726672833102768, 'layers_size': 448, 'dropout_p': 0.2529656285044678}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:17,625] Trial 24 finished with value: 0.4963025450706482 and parameters: {'lr': 0.05375923967532408, 'batch_size': 112, 'l2_reg': 0.08988548026752195, 'layers_size': 512, 'dropout_p': 0.33617466700280585}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:24,447] Trial 25 finished with value: 0.4763842225074768 and parameters: {'lr': 0.026964922851336247, 'batch_size': 80, 'l2_reg': 0.060122876455737904, 'layers_size': 320, 'dropout_p': 0.27358432327621884}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:30,227] Trial 26 finished with value: 0.4713088870048523 and parameters: {'lr': 0.01939076743319399, 'batch_size': 96, 'l2_reg': 0.0743098798157941, 'layers_size': 448, 'dropout_p': 0.20135225100456797}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:33,925] Trial 27 finished with value: 0.4797980785369873 and parameters: {'lr': 0.04526988807937652, 'batch_size': 128, 'l2_reg': 0.05244379591127843, 'layers_size': 64, 'dropout_p': 0.3177307932328759}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:39,734] Trial 28 finished with value: 0.4712180197238922 and parameters: {'lr': 0.009306413551614266, 'batch_size': 112, 'l2_reg': 0.07074878235063223, 'layers_size': 256, 'dropout_p': 0.3752441619375757}. Best is trial 18 with value: 0.46596238017082214.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:39:46,434] Trial 29 finished with value: 0.48001402616500854 and parameters: {'lr': 0.030495907831558394, 'batch_size': 80, 'l2_reg': 0.048253882108819715, 'layers_size': 448, 'dropout_p': 0.45148210517617204}. Best is trial 18 with value: 0.46596238017082214.\n",
      "[I 2024-11-27 16:39:46,436] A new study created in memory with name: no-name-ec9f052c-fa36-4f10-bc5a-6d71844d461d\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:04,844] Trial 0 finished with value: 0.5195750594139099 and parameters: {'lr': 0.028866026624570697, 'batch_size': 16, 'l2_reg': 0.08690318416729995, 'layers_size': 192, 'dropout_p': 0.6033521924477232}. Best is trial 0 with value: 0.5195750594139099.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:13,130] Trial 1 finished with value: 0.48247286677360535 and parameters: {'lr': 0.035804706756294685, 'batch_size': 64, 'l2_reg': 0.09902139343423406, 'layers_size': 64, 'dropout_p': 0.3478343845465469}. Best is trial 1 with value: 0.48247286677360535.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:19,173] Trial 2 finished with value: 0.48211270570755005 and parameters: {'lr': 0.03108824115682154, 'batch_size': 64, 'l2_reg': 0.02546004859558266, 'layers_size': 64, 'dropout_p': 0.45942549811174727}. Best is trial 2 with value: 0.48211270570755005.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:36,976] Trial 3 finished with value: 0.5517845153808594 and parameters: {'lr': 0.08936608055515852, 'batch_size': 16, 'l2_reg': 0.0677625096961852, 'layers_size': 384, 'dropout_p': 0.44495118942325584}. Best is trial 2 with value: 0.48211270570755005.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:47,953] Trial 4 finished with value: 0.47801443934440613 and parameters: {'lr': 0.010765929292109793, 'batch_size': 48, 'l2_reg': 0.05553529403969862, 'layers_size': 320, 'dropout_p': 0.4905639528423875}. Best is trial 4 with value: 0.47801443934440613.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:53,661] Trial 5 finished with value: 0.4733840227127075 and parameters: {'lr': 0.027083619967262964, 'batch_size': 112, 'l2_reg': 0.01648781142404296, 'layers_size': 128, 'dropout_p': 0.487640930654037}. Best is trial 5 with value: 0.4733840227127075.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:40:59,380] Trial 6 finished with value: 0.4774538278579712 and parameters: {'lr': 0.07476857784718033, 'batch_size': 96, 'l2_reg': 0.009433951123340976, 'layers_size': 384, 'dropout_p': 0.2490331734968042}. Best is trial 5 with value: 0.4733840227127075.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:03,632] Trial 7 finished with value: 0.48970913887023926 and parameters: {'lr': 0.0818777884806104, 'batch_size': 96, 'l2_reg': 0.05217609882730041, 'layers_size': 64, 'dropout_p': 0.3078255582823134}. Best is trial 5 with value: 0.4733840227127075.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:08,572] Trial 8 finished with value: 0.4697449207305908 and parameters: {'lr': 0.012303067954533554, 'batch_size': 128, 'l2_reg': 0.02141701199881216, 'layers_size': 256, 'dropout_p': 0.5110311262998906}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:12,566] Trial 9 finished with value: 0.4969644844532013 and parameters: {'lr': 0.08035911453612334, 'batch_size': 80, 'l2_reg': 0.09477635124062699, 'layers_size': 256, 'dropout_p': 0.518363525498797}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:20,498] Trial 10 finished with value: 0.49071741104125977 and parameters: {'lr': 0.06736561651124445, 'batch_size': 64, 'l2_reg': 0.037690989078774315, 'layers_size': 384, 'dropout_p': 0.3619350528174532}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:28,814] Trial 11 finished with value: 0.4708859920501709 and parameters: {'lr': 0.004579285911507045, 'batch_size': 64, 'l2_reg': 0.03208933035379871, 'layers_size': 128, 'dropout_p': 0.6538532939057146}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:41:55,921] Trial 12 finished with value: 0.554037868976593 and parameters: {'lr': 0.09941627148684556, 'batch_size': 16, 'l2_reg': 0.04082360368086804, 'layers_size': 128, 'dropout_p': 0.48650234049834895}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:09,973] Trial 13 finished with value: 0.4991031289100647 and parameters: {'lr': 0.07935436792123554, 'batch_size': 32, 'l2_reg': 0.001318789799991816, 'layers_size': 448, 'dropout_p': 0.541638411186707}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:13,157] Trial 14 finished with value: 0.47862178087234497 and parameters: {'lr': 0.057413498247927665, 'batch_size': 128, 'l2_reg': 0.01393122346701508, 'layers_size': 448, 'dropout_p': 0.38181976701771747}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:17,173] Trial 15 finished with value: 0.4773409962654114 and parameters: {'lr': 0.08335642175782719, 'batch_size': 112, 'l2_reg': 0.0012575590042397194, 'layers_size': 448, 'dropout_p': 0.26112318790040256}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:23,565] Trial 16 finished with value: 0.4925624430179596 and parameters: {'lr': 0.07073057523050735, 'batch_size': 96, 'l2_reg': 0.07492976474153733, 'layers_size': 192, 'dropout_p': 0.2459858252998129}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:39,324] Trial 17 finished with value: 0.47095537185668945 and parameters: {'lr': 0.005316134114719825, 'batch_size': 32, 'l2_reg': 0.03027650407789853, 'layers_size': 384, 'dropout_p': 0.4544410195767494}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:45,364] Trial 18 finished with value: 0.47650814056396484 and parameters: {'lr': 0.037704887169642334, 'batch_size': 80, 'l2_reg': 0.006681351962424825, 'layers_size': 128, 'dropout_p': 0.35565154061083937}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:42:52,450] Trial 19 finished with value: 0.49853065609931946 and parameters: {'lr': 0.0778796250624918, 'batch_size': 48, 'l2_reg': 0.07290016238431714, 'layers_size': 384, 'dropout_p': 0.259901863807908}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:02,030] Trial 20 finished with value: 0.4838106334209442 and parameters: {'lr': 0.022909258506148836, 'batch_size': 32, 'l2_reg': 0.016428386843607926, 'layers_size': 128, 'dropout_p': 0.5693415727680684}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:11,293] Trial 21 finished with value: 0.49658623337745667 and parameters: {'lr': 0.03600359101708455, 'batch_size': 32, 'l2_reg': 0.08677072271099498, 'layers_size': 320, 'dropout_p': 0.5527641650542476}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:16,216] Trial 22 finished with value: 0.47361648082733154 and parameters: {'lr': 0.016045437552956534, 'batch_size': 112, 'l2_reg': 0.08692873833124537, 'layers_size': 320, 'dropout_p': 0.22673033672880044}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:22,850] Trial 23 finished with value: 0.4886534810066223 and parameters: {'lr': 0.046281729423584064, 'batch_size': 80, 'l2_reg': 0.09092520320839921, 'layers_size': 192, 'dropout_p': 0.39481467041717766}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:50,836] Trial 24 finished with value: 0.5068829655647278 and parameters: {'lr': 0.04193737722403253, 'batch_size': 16, 'l2_reg': 0.06238859604867948, 'layers_size': 128, 'dropout_p': 0.3625874433843935}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:55,407] Trial 25 finished with value: 0.48952966928482056 and parameters: {'lr': 0.07279952735006998, 'batch_size': 96, 'l2_reg': 0.0835895902426502, 'layers_size': 384, 'dropout_p': 0.619999483166329}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:43:59,937] Trial 26 finished with value: 0.4799978733062744 and parameters: {'lr': 0.04812929713940406, 'batch_size': 128, 'l2_reg': 0.08184140443356745, 'layers_size': 384, 'dropout_p': 0.6127952636552607}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:44:05,253] Trial 27 finished with value: 0.4828035533428192 and parameters: {'lr': 0.05423555499044131, 'batch_size': 80, 'l2_reg': 0.025617633388437665, 'layers_size': 64, 'dropout_p': 0.20514482319862903}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:44:10,349] Trial 28 finished with value: 0.48755526542663574 and parameters: {'lr': 0.04808862587761181, 'batch_size': 112, 'l2_reg': 0.05381588175070455, 'layers_size': 384, 'dropout_p': 0.5752709962080824}. Best is trial 8 with value: 0.4697449207305908.\n",
      "<ipython-input-112-78713763ac08>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-112-78713763ac08>:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
      "<ipython-input-100-7e3e0bbc8fab>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
      "<ipython-input-100-7e3e0bbc8fab>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to('cuda')\n",
      "[I 2024-11-27 16:44:21,298] Trial 29 finished with value: 0.5033116340637207 and parameters: {'lr': 0.05775028238546057, 'batch_size': 48, 'l2_reg': 0.08313677180117472, 'layers_size': 256, 'dropout_p': 0.546600600102572}. Best is trial 8 with value: 0.4697449207305908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.011731233810189203, 'batch_size': 112, 'l2_reg': 0.0769591382325227, 'layers_size': 384, 'dropout_p': 0.20116368234441523}\n",
      "{'lr': 0.012303067954533554, 'batch_size': 128, 'l2_reg': 0.02141701199881216, 'layers_size': 256, 'dropout_p': 0.5110311262998906}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "class SearchModel(nn.Module):\n",
    "    def __init__(self, input_size, layer_size, dropout_p):\n",
    "        super(SearchModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, layer_size),\n",
    "            nn.BatchNorm1d(layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(layer_size, layer_size // 2),\n",
    "            nn.BatchNorm1d(layer_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "        )\n",
    "        self.layer3 = nn.Linear(layer_size // 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return torch.sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x, threshold: float = 0.5):\n",
    "        return (self.predict_proba(x) > threshold).to(torch.int32)\n",
    "\n",
    "\n",
    "def define_model(trial, input_size):\n",
    "    layer_size = trial.suggest_int(\"layers_size\", 64, 512, step=64)\n",
    "    dropout_p = trial.suggest_float(\"dropout_p\", 0.2, 0.7)\n",
    "    model = SearchModel(input_size, layer_size, dropout_p)\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_data(X_train, y_train, batch_size):\n",
    "    train_dataset = MyDataset(X_train, y_train)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 128, step=16)\n",
    "    l2_reg = trial.suggest_float(\"l2_reg\", 1e-5, 1e-1)\n",
    "\n",
    "    model = define_model(trial, X_train.shape[1]).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
    "\n",
    "    weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train.numpy().reshape(-1)),\n",
    "        y=y_train.numpy().reshape(-1),\n",
    "    )\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1]).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    train_dataloader = prepare_data(X_train, y_train, batch_size)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    steps_without_improvement = 0\n",
    "    early_stopping_patience = 5\n",
    "    for epoch_id in range(10):\n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(batch_x), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "            y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "            eval_result = evaluate_model(model, X_test_tensor, y_test_tensor, loss_fn)\n",
    "\n",
    "            if eval_result[\"loss\"] < best_val_loss:\n",
    "                best_val_loss = eval_result[\"loss\"]\n",
    "                steps_without_improvement = 0\n",
    "            else:\n",
    "                steps_without_improvement += 1\n",
    "                if steps_without_improvement >= early_stopping_patience:\n",
    "                    break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "study_default = optuna.create_study()\n",
    "study_default.optimize(objective, n_trials=30)\n",
    "\n",
    "study_random = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
    "study_random.optimize(objective, n_trials=30)\n",
    "\n",
    "print(study_default.best_params)\n",
    "print(study_random.best_params)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5d7af91182035c53be6efb3f9b18ffc3e259c9c524705249407647c970de949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
